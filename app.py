import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import re
from datetime import timedelta

@st.cache_data(show_spinner=False)
def load_tariff_df(file_id):
    """Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ” CSV Ğ· Google Drive, Ğ¿ĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ÑÑ” Ğ´Ğ°Ñ‚Ñƒ Ñ– Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” DataFrame"""
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
    df = pd.read_csv(url)
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"])
    df = df.sort_values("date")
    return df

st.set_page_config(page_title="CASES Dashboard", layout="wide")
st.title("CASES Dashboard")

# ğŸ“¦ Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ² Ñ– Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ½Ğ¸Ñ… Google Drive ID
tariff_files = {
    "Full Access 0UAH": "1XoUhnsGUeVL3qwHMYJbk4mpCn3lhoEkB",
    "Full Access 5UAH": "1ngAmfUoL3qYM6l_URNDECZRW35XC_thY",
    "Full Access 250UAH": "1G60JUAk_vQVXVQnjZF9uK2VwUbYDlK6P",
    "Full Access 350UAH": "1eYubeexGVF5MKJFZIF6ZOwEfDDad1zPB",
    "Full Access 390UAH": "1xeTeJV8JvOowE8JG5I6tog3euIKvDDNj",
    "Full Access 550UAH": "1b5fMQ_5Y522zJssO_AikhkLBTfI3p_Bf",
    "Full Access 1000UAH": "1mOZsP89AhTufFvG2nSmbV6w5GSOKyGVx",
    "Theory Only 0UAH": "1SyARqxHQzEPlK9GEuUvNV1SEFeghJ1pr",
    "Theory Only 250UAH": "1q4c0m434WK46Thei_pgkdVB5lLDnQqZz",
    "Theory Only 550UAH": "1eFhAfdSC2LOLX3tJX5BWyGM693d0ASyK",
}

# ğŸ§© ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ» Ğ´Ğ»Ñ Ğ²Ğ¸Ğ±Ğ¾Ñ€Ñƒ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²
selected_tariffs = st.multiselect(
    "ĞĞ±ĞµÑ€Ñ–Ñ‚ÑŒ Ñ‚Ğ°Ñ€Ğ¸Ñ„(Ğ¸)",
    options=list(tariff_files.keys()),
    default=["Full Access 0UAH"]
)

# ğŸ§¾ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ñ‚Ğ° Ğ¾Ğ±'Ñ”Ğ´Ğ½Ğ°Ğ½Ğ½Ñ CSV-Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ²
dfs = []
for tariff in selected_tariffs:
    file_id = tariff_files[tariff]
    csv_url = f"https://drive.google.com/uc?export=download&id={file_id}"
    df_part = pd.read_csv(csv_url)
    df_part["tariff_name"] = tariff  # Ğ´Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ Ğ· Ğ½Ğ°Ğ·Ğ²Ğ¾Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ

    # Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ Ğ· Ñ†Ñ–Ğ½Ğ¾Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ (Ğ²Ğ¸Ñ‚ÑĞ³ÑƒÑ”Ğ¼Ğ¾ Ğ· Ğ½Ğ°Ğ·Ğ²Ğ¸)
    match = re.search(r"(\d+)UAH", tariff)
    if match:
        df_part["price"] = int(match.group(1))
    else:
        df_part["price"] = 0  # ÑĞºÑ‰Ğ¾ Ñ€Ğ°Ğ¿Ñ‚Ğ¾Ğ¼ Ğ½ĞµĞ¼Ğ°Ñ” Ñ†Ñ–Ğ½Ğ¸ Ğ² Ğ½Ğ°Ğ·Ğ²Ñ– Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ

    dfs.append(df_part)

# ğŸ§® ĞĞ±'Ñ”Ğ´Ğ½ÑƒÑ”Ğ¼Ğ¾ Ğ²ÑÑ– Ğ¾Ğ±Ñ€Ğ°Ğ½Ñ– Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ² Ğ¾Ğ´Ğ½Ñƒ
df = pd.concat(dfs, ignore_index=True)

# ğŸ—“ ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ´Ğ°Ñ‚Ğ¸
df["date"] = pd.to_datetime(df["date"], errors="coerce")
df = df.dropna(subset=["date"])

# ğŸ“† Ğ”Ñ–Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ñ… Ğ´Ğ°Ñ‚
min_date = df["date"].min()
max_date = df["date"].max()

# ğŸ” ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ» Ğ· ĞºĞ°Ğ»ĞµĞ½Ğ´Ğ°Ñ€ĞµĞ¼ (Ğ¾ÑÑ‚Ğ°Ğ½Ğ½Ñ– 30 Ğ´Ğ½Ñ–Ğ² Ğ·Ğ° Ğ·Ğ°Ğ¼Ğ¾Ğ²Ñ‡ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼)
from datetime import datetime

# ğŸ“… Ğ¡ÑŒĞ¾Ğ³Ğ¾Ğ´Ğ½Ñ–ÑˆĞ½Ñ–Ğ¹ Ğ´ĞµĞ½ÑŒ
today = pd.to_datetime(datetime.today().date())
min_date = df["date"].min()
max_data_date = df["date"].max()

st.sidebar.header("Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€ Ğ·Ğ° Ğ´Ğ°Ñ‚Ğ¾Ñ")

# ğŸ§­ Ğ’Ğ¸Ğ¿Ğ°Ğ´Ğ°ÑÑ‡Ğ¸Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñ–Ğ²
preset_option = st.sidebar.selectbox(
    "Ğ¨Ğ²Ğ¸Ğ´ĞºĞ¸Ğ¹ Ğ²Ğ¸Ğ±Ñ–Ñ€ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ:",
    (
        "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 30 Ğ´Ğ½Ñ–Ğ²",
        "ĞŸĞ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ğ¼Ñ–ÑÑÑ†ÑŒ",
        "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 3 Ğ¼Ñ–ÑÑÑ†Ñ–",
        "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 6 Ğ¼Ñ–ÑÑÑ†Ñ–Ğ²",
        "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ–Ğ¹ Ñ€Ñ–Ğº",
        "Ğ’ĞµÑÑŒ Ñ‡Ğ°Ñ"
    )
)

# ğŸ” ĞĞ±Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– Ğ²Ğ¸Ğ±Ğ¾Ñ€Ñƒ
if preset_option == "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 30 Ğ´Ğ½Ñ–Ğ²":
    end_default = min(today, max_data_date)
    start_default = end_default - timedelta(days=30)

elif preset_option == "ĞŸĞ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ğ¼Ñ–ÑÑÑ†ÑŒ":
    first_day_this_month = today.replace(day=1)
    last_day_prev_month = first_day_this_month - timedelta(days=1)
    start_default = last_day_prev_month.replace(day=1)
    end_default = last_day_prev_month

elif preset_option == "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 3 Ğ¼Ñ–ÑÑÑ†Ñ–":
    end_default = min(today, max_data_date)
    start_default = end_default - pd.DateOffset(months=3)

elif preset_option == "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ– 6 Ğ¼Ñ–ÑÑÑ†Ñ–Ğ²":
    end_default = min(today, max_data_date)
    start_default = end_default - pd.DateOffset(months=6)

elif preset_option == "ĞÑÑ‚Ğ°Ğ½Ğ½Ñ–Ğ¹ Ñ€Ñ–Ğº":
    end_default = min(today, max_data_date)
    start_default = end_default - pd.DateOffset(years=1)

elif preset_option == "Ğ’ĞµÑÑŒ Ñ‡Ğ°Ñ":
    start_default = min_date
    end_default = max_data_date

# ğŸ“† ĞšĞ°Ğ»ĞµĞ½Ğ´Ğ°Ñ€ Ğ· Ğ¿ĞµÑ€ĞµĞ´Ğ·Ğ°Ğ¿Ğ¾Ğ²Ğ½ĞµĞ½Ğ¸Ğ¼ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ğ¾Ğ¼
start_date, end_date = st.sidebar.date_input(
    "ĞĞ±Ğ¾ Ğ¾Ğ±ĞµÑ€Ñ–Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½Ñƒ:",
    value=[start_default, end_default],
    min_value=min_date,
    max_value=max_data_date
)

# Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ğ´Ğ»Ñ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ
cols_to_convert = [
    "start", "new", "reactivated",
    "upgradedEnter", "downgradedEnter",
    "end", "upgradedExit", "downgradedExit"
]

# ğŸ” Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ñ–Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ·Ğ° Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¸Ğ¼ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ğ¾Ğ¼
mask = (df["date"] >= pd.to_datetime(start_date)) & (df["date"] <= pd.to_datetime(end_date))
filtered_raw = df.loc[mask].copy()

# ğŸ”§ ĞŸĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº Ğ½Ğ° Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ– Ñ‚Ğ¸Ğ¿Ğ¸
for col in cols_to_convert:
    filtered_raw[col] = pd.to_numeric(filtered_raw.get(col, 0), errors="coerce").fillna(0)

# ĞĞ³Ñ€ĞµĞ³ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ñ– Ğ´Ğ»Ñ Ğ²ÑÑ–Ñ… Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¸Ñ… Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²
aggregated_df = (
    filtered_raw
    .groupby("date", as_index=False)[cols_to_convert]
    .sum()
)

# Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº Churned Users
aggregated_df["Churned Users"] = (
    aggregated_df["start"]
    + aggregated_df["new"]
    + aggregated_df["reactivated"]
    + aggregated_df["upgradedEnter"]
    + aggregated_df["downgradedEnter"]
    - aggregated_df["end"]
    - aggregated_df["upgradedExit"]
    - aggregated_df["downgradedExit"]
).clip(lower=0)

# ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ñ‚Ğ° ĞºÑ–Ğ½ĞµÑ†ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ
start_value_row = df[df["date"] == pd.to_datetime(start_date)]
start_value = int(
    aggregated_df.loc[
        aggregated_df["date"] == pd.to_datetime(start_date),
        "start"
    ].sum()
) if not aggregated_df.empty else "â€”"

end_value_row = df[df["date"] == pd.to_datetime(end_date)]
end_value = int(
    aggregated_df.loc[
        aggregated_df["date"] == pd.to_datetime(end_date),
        "end"
    ].sum()
) if not aggregated_df.empty else "â€”"

# ğŸ“ˆ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ·Ğ° ÑÑƒĞ¼Ğ¾Ñ
new_subs = int(aggregated_df["new"].sum())
reactivated = int(aggregated_df["reactivated"].sum())
upgraded = int(aggregated_df["upgradedEnter"].sum())
downgraded = int(aggregated_df["downgradedEnter"].sum())
churned_total= int(aggregated_df["Churned Users"].sum())

# ğŸ” Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº Churned Users Ğ¿Ğ¾ Ğ´Ğ½ÑÑ…
churned_series = (
    aggregated_df["start"]
    + aggregated_df["new"]
    + aggregated_df["reactivated"]
    + aggregated_df["upgradedEnter"]
    + aggregated_df["downgradedEnter"]
    - aggregated_df["end"]
    - aggregated_df["upgradedExit"]
    - aggregated_df["downgradedExit"]
).clip(lower=0)

churned_total = int(churned_series.sum())

# ğŸ“Œ Ğ’Ğ¸Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² Ğ¾Ğ´Ğ¸Ğ½ Ñ€ÑĞ´
st.subheader("ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸")
col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
col1.metric("ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºÑ–Ğ²\nĞ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ", start_value)
col2.metric("ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºÑ–Ğ²\nĞ½Ğ° ĞºÑ–Ğ½ĞµÑ†ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ", end_value)
col3.metric("ĞĞ¾Ğ²Ğ¸Ñ…\nĞ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºÑ–Ğ²", new_subs)
col4.metric("Ğ ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ…\nĞ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºÑ–Ğ²", reactivated)
col5.metric("Upgrade\n(Ğ²Ñ…Ñ–Ğ´)", upgraded)
col6.metric("Downgrade\n(Ğ²Ñ…Ñ–Ğ´)", downgraded)
col7.metric("Churned\nUsers", churned_total)

# â• Ğ”Ğ¾Ğ´Ğ°Ğ²Ğ°Ğ½Ğ½Ñ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Churned Users Ğ´Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–
aggregated_df["Churned Users"] = churned_series

# ğŸ“ˆ Ğ“Ñ€Ğ°Ñ„Ñ–Ğº "Users"
st.subheader("ĞšĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–")

fig = px.line(
    aggregated_df,
    x="date",
    y=["start", "new", "reactivated", "Churned Users"],
    markers=True,
)
fig.update_layout(xaxis_title=None, yaxis_title=None)
fig.update_xaxes(tickmode="linear", tickangle=45)

st.plotly_chart(fig, use_container_width=True)

# ğŸ’° Ğ¦Ñ–Ğ»ÑŒĞ¾Ğ²Ñ– Ğ¿Ğ¾ĞºĞ°Ğ·Ğ½Ğ¸ĞºĞ¸ Ğ¼Ñ–ÑÑÑ†Ñ
st.subheader("Ğ¦Ñ–Ğ»ÑŒĞ¾Ğ²Ñ– Ğ¿Ğ¾ĞºĞ°Ğ·Ğ½Ğ¸ĞºĞ¸ Ğ¼Ñ–ÑÑÑ†Ñ")

ad_budget = 5000  # Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ½Ğ¸Ğ¹ Ğ±ÑĞ´Ğ¶ĞµÑ‚

# MRR

# Ğ“Ñ€ÑƒĞ¿ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ñ– Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ Ñ‚Ğ° Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ…Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ ÑĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ start
mrr = 0
for tariff in selected_tariffs:
    # Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€ÑƒÑ”Ğ¼Ğ¾ Ğ°Ğ³Ñ€ĞµĞ³Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ°Ñ‚Ğ°Ñ„Ñ€ĞµĞ¹Ğ¼ Ğ¿Ğ¾ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ
    tariff_df = filtered_raw[filtered_raw["tariff_name"] == tariff]
    if not tariff_df.empty:
        avg_start = tariff_df["start"].mean()
        price = tariff_df["price"].iloc[0]  # Ñ†Ñ–Ğ½Ğ° Ğ´Ğ»Ñ Ñ†ÑŒĞ¾Ğ³Ğ¾ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ
        mrr += avg_start * price

mrr = int(round(mrr))

# Churn Rate
try:
    churn_rate = churned_total / start_value
    churn_rate_str = f"{churn_rate:.1%}"
except (ZeroDivisionError, TypeError):
    churn_rate = None
    churn_rate_str = "â€”"

# Growth Rate
# ğŸ’¡ Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº MRR Ğ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ñ– ĞºÑ–Ğ½ĞµÑ†ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ Ğ· ÑƒÑ€Ğ°Ñ…ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼ ÑƒÑÑ–Ñ… Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²

def calc_mrr_on_date(date, df):
    mrr = 0
    for tariff in selected_tariffs:
        sub = df[(df["date"] == pd.to_datetime(date)) & (df["tariff_name"] == tariff)]
        if not sub.empty:
            start = sub["start"].values[0]
            price = sub["price"].values[0]
            mrr += start * price
    return mrr

mrr_first = calc_mrr_on_date(start_date, filtered_raw)
mrr_last  = calc_mrr_on_date(end_date, filtered_raw)

try:
    growth_rate = (mrr_last - mrr_first) / mrr_first if mrr_first != 0 else 0
    growth_rate_str = f"{growth_rate:.1%}"
except ZeroDivisionError:
    growth_rate_str = "â€”"

# Lifetime
if churn_rate and churn_rate != 0:
    lifetime = 1 / churn_rate
    lifetime_str = f"{lifetime:.1f}"
else:
    lifetime = None
    lifetime_str = "â€”"

# ARPPU â€” ÑĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ğ´Ğ¾Ñ…Ñ–Ğ´ Ğ½Ğ° Ğ¿Ğ»Ğ°Ñ‚Ğ½Ğ¸ĞºĞ°
try:
    arppu = mrr / end_value if end_value else None
    arppu_str = f"{arppu:.2f}" if arppu is not None else "â€”"
except ZeroDivisionError:
    arppu = None
    arppu_str = "â€”"

# LTV â€” Ğ¶Ğ¸Ñ‚Ñ‚Ñ”Ğ²Ğ¸Ğ¹ Ñ†Ğ¸ĞºĞ» ĞºĞ»Ñ–Ñ”Ğ½Ñ‚Ğ°
if lifetime and arppu:
    ltv = lifetime * arppu
    ltv_str = f"{int(ltv)}"
else:
    ltv = None
    ltv_str = "â€”"

# CAC â€” Ğ²Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ Ğ·Ğ°Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºĞ°
try:
    cac = ad_budget / new_subs if new_subs else None
    cac_str = f"{cac:.2f}" if cac is not None else "â€”"
except ZeroDivisionError:
    cac = None
    cac_str = "â€”"

# LTV / CAC
try:
    ltv_cac = ltv / cac if (ltv is not None and cac) else None
    ltv_cac_str = f"{ltv_cac:.2f}" if ltv_cac is not None else "â€”"
except ZeroDivisionError:
    ltv_cac_str = "â€”"

# ğŸ§® Ğ’Ğ¸Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ Ñ†Ñ–Ğ»ÑŒĞ¾Ğ²Ğ¸Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
col1.metric("MRR", mrr)
col2.metric("Churn rate", churn_rate_str)
col3.metric("Growth rate", growth_rate_str)
col4.metric("Lifetime (Ğ¼Ñ–Ñ.)", lifetime_str)
col5.metric("LTV", ltv_str)
#col6.metric("CAC", cac_str)
#col7.metric("LTV / CAC", ltv_cac_str)

# ğŸ“Š Ğ“Ñ€Ğ°Ñ„Ñ–Ğº MRR Ğ¿Ğ¾ Ğ´Ğ½ÑÑ…
st.subheader("MRR")

# Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ Ğ² aggregated_df ÑÑ‚Ğ¾Ğ²Ğ¿ĞµÑ†ÑŒ MRR Ğ¿Ğ¾ Ğ´Ğ½ÑÑ… (Ğ· ÑƒÑ€Ğ°Ñ…ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼ Ñ†Ñ–Ğ½ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²)
def calc_mrr_day(day):
    # day â€” Ğ´Ğ°Ñ‚Ğ°
    mrr_day = 0
    for tariff in selected_tariffs:
        # Ğ—Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ²ÑÑ– Ñ€ÑĞ´ĞºĞ¸ Ğ² filtered_raw Ğ· Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾Ñ Ğ´Ğ°Ñ‚Ğ¾Ñ Ñ– Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ¾Ğ¼
        sub = filtered_raw[(filtered_raw["date"] == day) & (filtered_raw["tariff_name"] == tariff)]
        if not sub.empty:
            start = sub["start"].values[0]
            price = sub["price"].values[0]
            mrr_day += start * price
    return mrr_day

aggregated_df["MRR"] = aggregated_df["date"].apply(calc_mrr_day)

# Ğ‘ÑƒĞ´ÑƒÑ”Ğ¼Ğ¾ Ğ³Ñ€Ğ°Ñ„Ñ–Ğº Ğ·Ğ° Ğ½Ğ¾Ğ²Ğ¸Ğ¼ ÑÑ‚Ğ¾Ğ²Ğ¿Ñ‡Ğ¸ĞºĞ¾Ğ¼
fig_mrr = px.line(
    aggregated_df,
    x="date",
    y="MRR",
    markers=True
)
fig_mrr.update_layout(xaxis_title=None, yaxis_title=None)
fig_mrr.update_xaxes(tickmode="linear", tickangle=45)

st.plotly_chart(fig_mrr, use_container_width=True)

# ğŸ“‹ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ´Ğ°Ğ½Ğ¸Ñ…
# st.subheader("Ğ”Ğ°Ğ½Ñ– Ğ·Ğ° Ğ²Ğ¸Ğ±Ñ€Ğ°Ğ½Ğ¸Ğ¹ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´:")
# st.dataframe(aggregated_df, use_container_width=True)

# ğŸ“Š ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²
st.subheader("ĞŸĞ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²")

# ğŸ§¾ ĞŸĞ¾ĞºĞ°Ğ·Ğ½Ğ¸ĞºĞ¸, ÑĞºÑ– Ñ…Ğ¾Ñ‡ĞµĞ¼Ğ¾ Ğ¿Ğ¾Ñ€Ñ–Ğ²Ğ½ÑĞ²Ğ°Ñ‚Ğ¸
metrics_list = [
    "ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ",
    "ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºĞ¸ Ğ½Ğ° ĞºÑ–Ğ½ĞµÑ†ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ",
    "ĞĞ¾Ğ²Ñ– ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–",
    "Ğ ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²Ğ°Ğ½Ñ– ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–",
    "Churned users",
    "MRR",
    "Churn rate",
    "Lifetime (Ğ¼Ñ–Ñ.)",
    "ARPPU",
    "LTV",
    "CAC",
    "LTV / CAC"
]

# ğŸ”€ Ğ“Ñ€ÑƒĞ¿ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñ–Ğ²
tariff_names = list(tariff_files.keys())
theory_tariffs = [name for name in tariff_names if "Theory Only" in name]
full_tariffs = [name for name in tariff_names if "Full Access" in name]

# ğŸ§± Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºÑ–Ğ² MultiIndex
multi_columns = pd.MultiIndex.from_tuples([
    ("Ğ›Ğ¸ÑˆĞµ Ñ‚ĞµĞ¾Ñ€Ñ–Ñ", name.replace("Theory Only ", "").replace("UAH", "Ğ³Ñ€Ğ½")) for name in theory_tariffs
] + [
    ("ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿", name.replace("Full Access ", "").replace("UAH", "Ğ³Ñ€Ğ½")) for name in full_tariffs
])

# ğŸ“ ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ½Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ· MultiIndex-ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°Ğ¼Ğ¸
data = pd.DataFrame(index=metrics_list, columns=multi_columns)

# ğŸ”„ ĞŸÑ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿Ğ¾ Ğ²ÑÑ–Ğ¼ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ°Ğ¼ Ñ– Ğ¾Ğ±Ñ‡Ğ¸ÑĞ»ÑÑ”Ğ¼Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
for tariff in theory_tariffs + full_tariffs:
    file_id = tariff_files[tariff]
    csv_url = f"https://drive.google.com/uc?export=download&id={file_id}"

    try:
        df_tariff = load_tariff_df(file_id)

        # Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ price, Ğ²Ğ¸Ñ‚ÑĞ³ÑƒÑÑ‡Ğ¸ Ñ†Ñ–Ğ½Ñƒ Ğ· Ğ½Ğ°Ğ·Ğ²Ğ¸ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ
        match = re.search(r"(\d+)UAH", tariff)
        if match:
            df_tariff["price"] = int(match.group(1))
        else:
            df_tariff["price"] = 0        

        # Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ñ–
        mask = (df_tariff["date"] >= pd.to_datetime(start_date)) & (df_tariff["date"] <= pd.to_datetime(end_date))
        df_filtered = df_tariff[mask].copy()

        # ĞŸĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ½Ğ° Ñ‡Ğ¸ÑĞ»Ğ°
        for col in cols_to_convert:
            if col in df_filtered.columns:
                df_filtered[col] = pd.to_numeric(df_filtered[col], errors="coerce").fillna(0)
            else:
                df_filtered[col] = 0

        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        start_row = df_tariff[df_tariff["date"] == pd.to_datetime(start_date)]
        end_row = df_tariff[df_tariff["date"] == pd.to_datetime(end_date)]

        start_val = int(start_row["start"].values[0]) if not start_row.empty else 0
        end_val = int(end_row["end"].values[0]) if not end_row.empty else 0
        new_val = int(df_filtered["new"].sum())
        reactivated_val = int(df_filtered["reactivated"].sum())

        churned_series = (
            df_filtered["start"]
            + df_filtered["new"]
            + df_filtered["reactivated"]
            + df_filtered["upgradedEnter"]
            + df_filtered["downgradedEnter"]
            - df_filtered["end"]
            - df_filtered["upgradedExit"]
            - df_filtered["downgradedExit"]
        ).clip(lower=0)

        churned_val = int(churned_series.sum())
        if not df_filtered.empty:
            price = df_filtered["price"].iloc[0]
            mrr_val = int(df_filtered["start"].mean() * price)
        else:
            mrr_val = 0

        churn_rate = churned_val / start_val if start_val else None
        lifetime = 1 / churn_rate if churn_rate else None
        arppu = mrr_val / end_val if end_val else None
        ltv = lifetime * arppu if lifetime and arppu else None
        cac = ad_budget / new_val if new_val else None
        ltv_cac = ltv / cac if ltv and cac else None

        # Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–
        col_label = tariff.replace("Theory Only ", "").replace("Full Access ", "").replace("UAH", "Ğ³Ñ€Ğ½")
        col_group = "Ğ›Ğ¸ÑˆĞµ Ñ‚ĞµĞ¾Ñ€Ñ–Ñ" if "Theory Only" in tariff else "ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿"

        # Ğ—Ğ°Ğ¿Ğ¸Ñ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½ÑŒ Ñƒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ
        data.loc["ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ", (col_group, col_label)] = start_val
        data.loc["ĞŸÑ–Ğ´Ğ¿Ğ¸ÑĞ½Ğ¸ĞºĞ¸ Ğ½Ğ° ĞºÑ–Ğ½ĞµÑ†ÑŒ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´Ñƒ", (col_group, col_label)] = end_val
        data.loc["ĞĞ¾Ğ²Ñ– ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–", (col_group, col_label)] = new_val
        data.loc["Ğ ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²Ğ°Ğ½Ñ– ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–", (col_group, col_label)] = reactivated_val
        data.loc["Churned users", (col_group, col_label)] = churned_val
        data.loc["MRR", (col_group, col_label)] = mrr_val
        data.loc["Churn rate", (col_group, col_label)] = f"{churn_rate:.1%}" if churn_rate is not None else "â€”"
        data.loc["Lifetime (Ğ¼Ñ–Ñ.)", (col_group, col_label)] = f"{lifetime:.1f}" if lifetime is not None else "â€”"
        data.loc["ARPPU", (col_group, col_label)] = f"{arppu:.0f}" if arppu is not None else "â€”"
        data.loc["LTV", (col_group, col_label)] = f"{ltv:.0f}" if ltv is not None else "â€”"
        data.loc["CAC", (col_group, col_label)] = f"{cac:.2f}" if cac is not None else "â€”"
        data.loc["LTV / CAC", (col_group, col_label)] = f"{ltv_cac:.2f}" if ltv_cac is not None else "â€”"

    except Exception as e:
        st.warning(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ğ°Ğ±Ğ¾ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸ Ğ´Ğ°Ğ½Ñ– Ğ´Ğ»Ñ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ñƒ {tariff}: {e}")




#Ğ¢Ğ¸Ğ¼Ñ‡Ğ°ÑĞ¾Ğ²Ğ¾ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ²Ğ° Ñ€ÑĞ´ĞºĞ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–
hide_metrics = ["CAC", "LTV / CAC"]
data = data.drop(index=hide_metrics)






# ğŸ–¼ Ğ’Ğ¸Ğ²Ñ–Ğ´ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ¾Ñ— Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ· Ñ†ĞµĞ½Ñ‚Ñ€ÑƒĞ²Ğ°Ğ½Ğ½ÑĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºÑ–Ğ²
st.markdown(
    data.style
    .set_table_styles([
        {"selector": "thead th", "props": [("text-align", "center")]}
    ])
    .to_html(),
    unsafe_allow_html=True
)